{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Hadoop\n",
        "\n",
        "![Hadoop Logo](https://github.com/pnavaro/big-data/blob/master/notebooks/images/hadoop.png?raw=1)"
      ],
      "metadata": {
        "id": "2aZnBPqcrsqr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Introdução"
      ],
      "metadata": {
        "id": "uEg1qPOoyAvp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![https://github.com/veekaybee/data-lake-talk/](https://github.com/pnavaro/big-data/blob/master/notebooks/images/bigdata.png?raw=1)\n",
        "\n",
        "- Framework para executar aplicativos em grandes clusters.\n",
        "- O framework Hadoop fornece de forma transparente aos aplicativos confiabilidade e movimentação de dados.\n",
        "- O Hadoop implementa o paradigma computacional chamado **Map/Reduce**, onde o aplicativo é dividido em muitos pequenos fragmentos de trabalho, cada um dos quais pode ser executado ou reexecutado em qualquer nó no cluster.\n",
        "- Ele fornece um sistema de arquivos distribuído (HDFS) que armazena dados nos nós de computação, fornecendo largura de banda agregada muito alta em todo o cluster.\n",
        "- Tanto o MapReduce quanto o **Hadoop Distributed File System** são projetados para que as falhas de nó sejam automaticamente tratadas pelo framework."
      ],
      "metadata": {
        "id": "aHBU-XQgO30O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Instalando o Java 8"
      ],
      "metadata": {
        "id": "Kxt9UbTArwTC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hadoop é um framework de processamento de dados baseado em Java.\n",
        "\n",
        "O *OpenJDK* (versão *open source* do Java) é um ambiente de desenvolvimento para construir aplicativos, *applets* e componentes usando a linguagem de programação Java."
      ],
      "metadata": {
        "id": "eXp-IUxoGXEH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Verificando a versão do Java instalada\n",
        "!java -version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwH_9BC1ZIET",
        "outputId": "ba55592d-538b-483d-86d9-6528fb1807a2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "openjdk version \"11.0.24\" 2024-07-16\n",
            "OpenJDK Runtime Environment (build 11.0.24+8-post-Ubuntu-1ubuntu322.04)\n",
            "OpenJDK 64-Bit Server VM (build 11.0.24+8-post-Ubuntu-1ubuntu322.04, mixed mode, sharing)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instalando o Java 8 para melhor compatibilidade com o Hadoop"
      ],
      "metadata": {
        "id": "KmHd4GpDWOjX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "_UOxDVi9ceCm"
      },
      "outputs": [],
      "source": [
        "#Instalando o java 8\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Alterando a versão padrão do Java no sistema"
      ],
      "metadata": {
        "id": "HTZN58Mv1hlG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Alterando a versão do Java para usar como padrão (escolha a opção 2)\n",
        "!update-alternatives --config java"
      ],
      "metadata": {
        "id": "BSMxNJlea1K7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Alterando a versão do Javac para usar como padrão (escolha a opção 2)\n",
        "!update-alternatives --config javac"
      ],
      "metadata": {
        "id": "L9_5cIQGlg2G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Alterando a versão do jps para usar como padrão (escolha a opção 2)\n",
        "!update-alternatives --config jps"
      ],
      "metadata": {
        "id": "Mo4Dnbf82vjj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking Java default version\n",
        "!java -version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AWunFxU8b9gh",
        "outputId": "90ba1f0b-62d3-4294-fa93-96eef0a9b6d4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "openjdk version \"1.8.0_422\"\n",
            "OpenJDK Runtime Environment (build 1.8.0_422-8u422-b05-1~22.04-b05)\n",
            "OpenJDK 64-Bit Server VM (build 25.422-b05, mixed mode)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Criando as variáveis ​​de ambiente relacionadas ao Java"
      ],
      "metadata": {
        "id": "K4xYHnO72Gwo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**JAVA_HOME** é uma variável de ambiente do sistema operacional que aponta para o local do sistema de arquivos onde o JDK ou JRE foi instalado."
      ],
      "metadata": {
        "id": "vBzOrjQ3nRlI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Encontrando o caminho Java padrão\n",
        "!readlink -f /usr/bin/java | sed \"s:bin/java::\""
      ],
      "metadata": {
        "id": "kXFJVGrIdYbW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Importando módulo os (sistema operacional)\n",
        "import os\n",
        "#Criando as variáveis ​​de ambiente\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"JRE_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64/jre\"\n",
        "os.environ[\"PATH\"] += \":$JAVA_HOME/bin:$JRE_HOME/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbin\""
      ],
      "metadata": {
        "id": "0am0Ybf6cyvX"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Instalando o Hadoop 3.2.3"
      ],
      "metadata": {
        "id": "qCeL0IBlrnoF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Download do Hadoop 3.2.3\n",
        "!wget -q https://archive.apache.org/dist/hadoop/common/hadoop-3.2.3/hadoop-3.2.3.tar.gz"
      ],
      "metadata": {
        "id": "t6w9exw9c11y"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Descompactando o arquivo\n",
        "!sudo tar -xzf hadoop-3.2.3.tar.gz\n",
        "\n",
        "#Removendo o arquivo compactado\n",
        "!rm hadoop-3.2.3.tar.gz"
      ],
      "metadata": {
        "id": "Ngsl1XNPdOP0"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "O local padrão para instalar o Hadoop é:\n",
        "\n",
        "*   /usr/local\n",
        "*   /opt"
      ],
      "metadata": {
        "id": "PmoGNehEKW_X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Copiando os arquivos do hadoop para --> /usr/local/\n",
        "!cp -r hadoop-3.2.3/ /usr/local/\n",
        "#-r copia diretórios recursivamente"
      ],
      "metadata": {
        "id": "bb1_Uve9dUX1"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Explorando o diretório --> hadoop-3.2.3/etc/hadoop\n",
        "!ls /usr/local/hadoop-3.2.3/etc/hadoop\n",
        "#Podemos ver vários arquivos de configuração do hadoop"
      ],
      "metadata": {
        "id": "YJqjMBenAqWf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfe6be80-bf32-4e23-ad90-8ed8a283dcaf"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "capacity-scheduler.xml\t\t  httpfs-log4j.properties     mapred-site.xml\n",
            "configuration.xsl\t\t  httpfs-signature.secret     shellprofile.d\n",
            "container-executor.cfg\t\t  httpfs-site.xml\t      ssl-client.xml.example\n",
            "core-site.xml\t\t\t  kms-acls.xml\t\t      ssl-server.xml.example\n",
            "hadoop-env.cmd\t\t\t  kms-env.sh\t\t      user_ec_policies.xml.template\n",
            "hadoop-env.sh\t\t\t  kms-log4j.properties\t      workers\n",
            "hadoop-metrics2.properties\t  kms-site.xml\t\t      yarn-env.cmd\n",
            "hadoop-policy.xml\t\t  log4j.properties\t      yarn-env.sh\n",
            "hadoop-user-functions.sh.example  mapred-env.cmd\t      yarnservice-log4j.properties\n",
            "hdfs-site.xml\t\t\t  mapred-env.sh\t\t      yarn-site.xml\n",
            "httpfs-env.sh\t\t\t  mapred-queues.xml.template\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Precisamos configurar algumas coisas antes de executar o Hadoop. Ou seja, precisamos adicionar ou modificar alguns parâmetros nesses arquivos de configuração para operar o Hadoop em qualquer modo que quisermos."
      ],
      "metadata": {
        "id": "cx80yeBMBUDT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Configurando o arquivo **hadoop-env.sh**"
      ],
      "metadata": {
        "id": "0mFNgy1--JYr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**hadoop-env.sh** é um *script bash* que contém variáveis ​​de ambiente que são usadas nos scripts para executar o Hadoop"
      ],
      "metadata": {
        "id": "hLjfw00rCIFq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Visualizando o conteudo do aquivo --> hadoop-env.sh\n",
        "!cat /usr/local/hadoop-3.2.3/etc/hadoop/hadoop-env.sh"
      ],
      "metadata": {
        "id": "-JiNs3H7FrmI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A única variável de ambiente necessária é **JAVA_HOME**. Todas as outras são opcionais.\n",
        "\n",
        "Para especificar a variável JAVA_HOME em hadoop-env.sh, precisamos descomentar a linha export e atualizá-la com o diretório real.\n",
        "\n",
        "Neste caso, deve ficar assim:\n",
        "\n",
        "`export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64`"
      ],
      "metadata": {
        "id": "3o9SROCEHl72"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Adicionando o diretório do JAVA_HOME ao arquivo --> hadoop-env.sh\n",
        "!sed -i '/export JAVA_HOME=/a export JAVA_HOME=\\/usr\\/lib\\/jvm\\/java-8-openjdk-amd64' /usr/local/hadoop-3.2.3/etc/hadoop/hadoop-env.sh"
      ],
      "metadata": {
        "id": "TeCM3uiCXvF-"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Criando uma variável de ambiente que aponta para o diretório de instalação do Hadoop"
      ],
      "metadata": {
        "id": "sX6dPYTcMU5A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Variável de ambiente para o diretório do hadoop\n",
        "os.environ[\"HADOOP_HOME\"] = \"/usr/local/hadoop-3.2.3\""
      ],
      "metadata": {
        "id": "rNtD2mvkMs5x"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Configurando arquivos XML\n",
        "\n",
        "A maioria das configurações do Hadoop está contida em arquivos de configuração XML. Esses arquivos também são conhecidos como **recursos**.\n",
        "\n",
        "Eles têm a seguinte estrutura:\n",
        "\n",
        "\n",
        "```\n",
        "<configuration>\n",
        "...\n",
        "  <property>\n",
        "    <name>...</name>\n",
        "    <value>...</value>\n",
        "    <description>...</description>\n",
        "  </property>\n",
        "...\n",
        "</configuration>\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "dCws8A6MOC1K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A configuração do Hadoop é conduzida por dois tipos distintos de arquivos de configuração XLM:\n",
        "\n",
        "1. **Default** (somente leitura): *core-default.xml, hdfs-default.xml, mapred-default.xml, yarn-default.xml*. Esses arquivos nunca devem ser modificados.\n",
        "2. Arquivos de configuração **Site specific**: *core-site.xml, hdfs-site.xml, mapred-site.xml, yarn-site.xml*. Esses arquivos são carregados do caminho da classe e seus valores são usados ​​para substituir os valores correspondentes das propriedades nos arquivos de configuração padrão correspondentes."
      ],
      "metadata": {
        "id": "szhRwlUOQ9D3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Explorando os arquivos do diretório --> hadoop-3.2.3/etc/hadoop xml\n",
        "!ls $HADOOP_HOME/etc/hadoop/*.xml"
      ],
      "metadata": {
        "id": "zaUWrl0lN203"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cada componente no Hadoop é configurado usando um arquivo xml\n",
        "\n",
        "* core-site.xml: propriedades comuns\n",
        "* hdfs-site.xml: propriedades do HDFS\n",
        "* mapred-site.xml: propriedades do MapReduce\n",
        "* yarn-site.xml: propriedades do YARN\n",
        "\n",
        "Ao configurar esses arquivos xml adequadamente, o Hadoop pode ser executado em um dos três modos."
      ],
      "metadata": {
        "id": "SMbIY4UQr-Cc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Conteudo do arquivo --> core-site.xml file\n",
        "!cat $HADOOP_HOME/etc/hadoop/core-site.xml"
      ],
      "metadata": {
        "id": "3X2yMzJRTTbz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como podemos ver, nenhuma propriedade foi definida. Elas estão vazias por padrão. Então não há nada para sobrescrever e o Hadoop funcionará com as propriedades padrão."
      ],
      "metadata": {
        "id": "LlK_OhXOTwLa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Executando o Hadoop"
      ],
      "metadata": {
        "id": "j7iQ3JIqP9Av"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Com as propriedades de configuração padrão, o Hadoop é executado em um modo autônomo (*modo não distribuído*). Ou seja, o modo autônomo (também conhecido como modo local) é o modo padrão para o Hadoop.\n",
        "\n",
        "O sistema de arquivos e o executor de tarefas MapReduce local serão utilizados."
      ],
      "metadata": {
        "id": "xyNhcphwU326"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "O comando para executar um programa *Hadoop mapreduce* escrito em Java é:\n",
        "\n",
        "`$HADOOP_HOME/bin/hadoop jar <jar>`\n",
        "\n",
        "**jar** é uma ferramenta Java que empacota (e compacta) um conjunto de classes/pacotes em um único arquivo."
      ],
      "metadata": {
        "id": "M5sq5u4YMWYy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A instalação padrão já possui vários programas de exemplo do MapReduce que podemos usar."
      ],
      "metadata": {
        "id": "T0mlMcx90v3C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Explorando as ferramentas de mapreduce\n",
        "!ls $HADOOP_HOME/share/hadoop/mapreduce/*.jar"
      ],
      "metadata": {
        "id": "KDU32MA_1A3j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "076683b3-b1ea-4ffb-937a-6e4471457131"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/hadoop-3.2.3/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.2.3.jar\n",
            "/usr/local/hadoop-3.2.3/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.2.3.jar\n",
            "/usr/local/hadoop-3.2.3/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.2.3.jar\n",
            "/usr/local/hadoop-3.2.3/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.2.3.jar\n",
            "/usr/local/hadoop-3.2.3/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.2.3.jar\n",
            "/usr/local/hadoop-3.2.3/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.2.3.jar\n",
            "/usr/local/hadoop-3.2.3/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.2.3-tests.jar\n",
            "/usr/local/hadoop-3.2.3/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.2.3.jar\n",
            "/usr/local/hadoop-3.2.3/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.2.3.jar\n",
            "/usr/local/hadoop-3.2.3/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.2.3.jar\n",
            "/usr/local/hadoop-3.2.3/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.3.jar\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mapreduce examples"
      ],
      "metadata": {
        "id": "E1sibHPwHcIS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Explorando os exemplos de programas disponíveis\n",
        "!$HADOOP_HOME/bin/hadoop jar $HADOOP_HOME/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.3.jar"
      ],
      "metadata": {
        "id": "TbNQV5Id1VEW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "wordcount"
      ],
      "metadata": {
        "id": "ky8_JvARHoVH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como a descrição diz, o ***wordcount*** é um programa de mapeamento/redução (*map/reduce*) que conta as palavras nos arquivos de entrada."
      ],
      "metadata": {
        "id": "YOPq3tC91yRa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Uso do programa MapReduce de wordcount (contagem de palavras)\n",
        "!$HADOOP_HOME/bin/hadoop jar $HADOOP_HOME/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.3.jar wordcount"
      ],
      "metadata": {
        "id": "0FjXG_lX2UUB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Os parâmetros são um diretório de entrada onde o texto a ser analisado é alocado e um diretório de saída onde o programa irá alocar sua saída."
      ],
      "metadata": {
        "id": "XkqKpjQl24wx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Baixando um exemplo de texto para usar como entrada\n",
        "!wget -q https://www.mirrorservice.org/sites/ftp.ibiblio.org/pub/docs/books/gutenberg/1/0/101/101.txt"
      ],
      "metadata": {
        "id": "fOHl7Iz84eyt"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Executando o programa MapReduce wordcount\n",
        "#O diretório de saída será criado automaticamente\n",
        "!$HADOOP_HOME/bin/hadoop jar $HADOOP_HOME/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.3.jar wordcount /content/101.txt /content/saida"
      ],
      "metadata": {
        "id": "tgY1T-c45Vzg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Explorando o diretório de saída\n",
        "#part-r-00000 contém o resultado\n",
        "!ls /content/saida"
      ],
      "metadata": {
        "id": "51IBObej6BA6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Imprimindo o conteúdo do arquivo\n",
        "!cat /content/saida/part-r-00000"
      ],
      "metadata": {
        "id": "xNignWQADaJg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Imprimindo as primeiras 50 linhas\n",
        "!head -100 /content/saida/part-r-00000"
      ],
      "metadata": {
        "id": "ViiYYpJcUnjd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}